@begin Python_Data_Cleansing_Step2 @desc Python_Data_Cleansing
@in input_from_step1_open_refine @uri file:AirBNBV2.csv
@out output_to_sql_notebook @uri file:02_airbnb_step2_complete.csv
@begin get_file
@in input_from_step1_open_refine @uri file:demo_input.csv
@out airbnb_data @AS pd_airbnb_data
read file
file after open-refine step
@end get_file
@begin drop_columns_if_exist
@in airbnb_data @AS pd_airbnb_data
@out drop_columns_dataset @as pd_dropped_columns_dataset
@end drop_columns_if_exist
@begin mark_nightsLong
@in drop_columns_dataset @as pd_dropped_columns_dataset
@out dataset_marked_nights_long @as pd_marked_nights_long
mark where nights were long
@end mark_nightsLong
@begin mark_availability_365
@in drop_columns_dataset @as pd_marked_nights_long
@out dataset_marked_nights_long @as pd_marked_availability
@end mark_availability_365
@begin out_std
@PARAM df
@PARAM column
@out upper_bound @as upper_std
@out lower_bound @as lower_std
calculate the mean and standard deviation of the data frame
calculate the cutoff value
calculate the lower and upper bound value
Calculate the number of records below and above lower and above bound value respectively
@end out_std
@begin mark_quality_price_outlier
@in drop_columns_dataset @as pd_marked_availability
@in upper_std @as upper_std
@in lower_std @as lower_std
@out dataset_marked_price_outlier @as pd_marked_price_outlier
@end mark_quality_price_outlier
@begin clean_names
@in marked_price_outlier @as pd_marked_price_outlier
@out dataset_clean_names @as pd_clean_names
@end clean_names
@begin clean_30_days
@in clean_names @as pd_clean_names
@out dataset_clean_30_days @as pd_clean_30_days
@end clean_30_days
@begin remove_non_utf8
@in clean_names @as pd_clean_30_days
@out dataset_utf8 @as pd_utf8
@end remove_non_utf8
@begin remove_special_characters
@in dirty_col @as dirty_col
@out clean_col @as clean_col
@end remove_special_characters
@begin clean_remove_special_characters
@in pd_utf8 @as pd_utf8
@out dirty_col @as dirty_col
@in clean_col @as clean_col
@out dataset_no_spec_chars @as pd_no_spec_chars
@end clean_remove_special_characters
@begin remove_consecutive_spaces
@in dirty_col @as dirty_col_cons
@out clean_col @as clean_col_cons
@end remove_consecutive_spaces
@begin clean_consecutive_spaces
@in dataset_no_spec_chars @as pd_no_spec_chars
@out dataset_no_consec_spaces @as pd_no_consec_spaces
@out dirty_col @as dirty_col_cons
@in clean_col @as clean_col_cons
@end clean_consecutive_spaces
@begin trim_head_tail_space
@in dirty_col @as dirty_col_trim
@out clean_col @as clean_col_trim
@end trim_head_tail_space
@begin clean_head_tail_spaces
@in dataset_no_consec_spaces @as pd_no_consec_spaces
@out dataset_trim_spaces @as pd_trim_spaces
@out dirty_col @as dirty_col_trim
@in clean_col @as clean_col_trim
@end clean_head_tail_spaces
@begin clean_empty_names
@in dataset_trim_spaces @as pd_trim_spaces
@out dataset_clean_empty_names @as pd_clean_empty_names
@end clean_empty_names
@begin clean_mark_missing
@in dataset_clean_empty_names @as pd_clean_empty_names
@out dataset_mark_missing @as pd_mark_missing
## Create missing indicator for features with missing data
## Based on the indicator, count number of Nan values in each row
@end clean_mark_missing
@begin clean_rename_name_columns
@in dataset_mark_missing @as pd_mark_missing
@out dataset_rename_nam_cols @as pd_rename_nam_cols
@end clean_rename_name_columns
@begin clean_reviews_per_month
@in dataset_rename_nam_cols @as pd_rename_nam_cols
@out dataset_clean_rev_per_month @as pd_clean_rev_per_month
@end clean_reviews_per_month
@begin output_csv
@in dataset_clean_rev_per_month @as pd_clean_rev_per_month
@out output @as output_to_sql_notebook @uri  file:02_airbnb_step2_complete.csv
@end output_csv
Use a breakpoint in the code line below to debug your script.
Press Ctrl+F8 to toggle the breakpoint.
@end Python_Data_Cleansing_Step2
Press the green button in the gutter to run the script.
Demo of clean_name_and_date_workflow script
print(df_no_name.shape)
output_csv(df)
